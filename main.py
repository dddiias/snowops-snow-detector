import os
import json
from datetime import datetime
import time

import cv2
import numpy as np
import requests
from ultralytics import YOLO
from google import genai
from PIL import Image
from dotenv import load_dotenv

# ============== –û–ö–†–£–ñ–ï–ù–ò–ï ==============

load_dotenv()

if not os.getenv("GEMINI_API_KEY"):
    raise RuntimeError(
        "–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è GEMINI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. "
        "–°–æ–∑–¥–∞–π —Ñ–∞–π–ª .env —Å —Å—Ç—Ä–æ–∫–æ–π: GEMINI_API_KEY=–¢–í–û–ô_–ö–õ–Æ–ß"
    )

gemini_client = genai.Client()

# ============== –ù–ê–°–¢–†–û–ô–ö–ò ==============

VIDEO_SOURCE_URL = "rtsp://admin:Armat456321@194.26.239.249:555/Streaming/Channels/101"
YOLO_MODEL_PATH = "yolov8n.pt"

TRUCK_CLASS_ID = 7
CONFIDENCE_THRESHOLD = 0.55

CENTER_ZONE_START_X = 0.35
CENTER_ZONE_END_X = 0.65
CENTER_LINE_X = 0.5  # –∂—ë–ª—Ç–∞—è –ª–∏–Ω–∏—è

SNAPSHOT_BASE_DIR = "snapshots"

# —Ä–∞–∑–º–µ—Ä –æ–∫–Ω–∞ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
DISPLAY_WIDTH = 1280
DISPLAY_HEIGHT = 720

# –ø–æ—Ä–æ–≥ –¥–ª—è ¬´–¥–≤–∏–∂–µ—Ç—Å—è –≤–ø—Ä–∞–≤–æ¬ª
MIN_DIRECTION_DELTA = 5

GEMINI_MODEL = "gemini-2.5-flash"

# –±–µ–∫–µ–Ω–¥ SnowOps
BACKEND_ENDPOINT = "https://snowops-anpr-service.onrender.com/api/v1/anpr/events"
CAMERA_ID = "camera-001"   # –ø–æ–º–µ–Ω—è–µ—à—å –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–π ID –∫–∞–º–µ—Ä—ã

# =======================================


def init_model() -> YOLO:
    return YOLO(YOLO_MODEL_PATH)


def detect_truck_bbox(frame: np.ndarray, model: YOLO):
    """
    –ù–∞—Ö–æ–¥–∏—Ç bbox –≥—Ä—É–∑–æ–≤–∏–∫–∞ (truck).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (x1, y1, x2, y2) –∏–ª–∏ None.
    """
    results = model(frame, verbose=False)
    best_box = None
    best_area = 0.0

    for r in results:
        boxes = r.boxes
        if boxes is None:
            continue

        for b in boxes:
            cls_id = int(b.cls[0].item())
            conf = float(b.conf[0].item())

            if cls_id != TRUCK_CLASS_ID or conf < CONFIDENCE_THRESHOLD:
                continue

            x1, y1, x2, y2 = map(int, b.xyxy[0].tolist())
            area = (x2 - x1) * (y2 - y1)

            if area > best_area:
                best_area = area
                best_box = (x1, y1, x2, y2)

    return best_box


def check_center_zone(bbox, frame_width: int):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –ø–æ–ø–∞–ª –ª–∏ —Ü–µ–Ω—Ç—Ä bbox –≤ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –∫–æ—Ä–∏–¥–æ—Ä.
    """
    x1, y1, x2, y2 = bbox
    center_x = x1 + (x2 - x1) // 2

    zone_start_px = int(frame_width * CENTER_ZONE_START_X)
    zone_end_px = int(frame_width * CENTER_ZONE_END_X)

    in_zone = zone_start_px < center_x < zone_end_px
    return in_zone, center_x, zone_start_px, zone_end_px


_last_center_x = None


def is_moving_left_to_right(current_center_x: int) -> bool:
    """
    True, –µ—Å–ª–∏ –æ–±—ä–µ–∫—Ç –¥–≤–∏–∂–µ—Ç—Å—è —Å–ª–µ–≤–∞ –Ω–∞–ø—Ä–∞–≤–æ.
    –õ–û–ì–ò–ö–ê –ö–ê–ö –í –†–ê–ë–û–¢–ê–í–®–ï–ú –í–ê–†–ò–ê–ù–¢–ï.
    """
    global _last_center_x

    moved_right = False
    if _last_center_x is not None:
        if current_center_x - _last_center_x > MIN_DIRECTION_DELTA:
            moved_right = True

    _last_center_x = current_center_x
    return moved_right


def save_frame(frame: np.ndarray):
    """
    –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–∞–¥—Ä –≤ snapshots/YYYY-MM-DD/HH-MM-SS.jpg.
    """
    now = datetime.now()
    date_dir = os.path.join(SNAPSHOT_BASE_DIR, now.strftime("%Y-%m-%d"))
    os.makedirs(date_dir, exist_ok=True)

    filename = now.strftime("%H-%M-%S") + ".jpg"
    path = os.path.join(date_dir, filename)

    cv2.imwrite(path, frame)
    return path, now


def analyze_snow_gemini(image_path: str) -> dict:
    """
    –ê–Ω–∞–ª–∏–∑ –æ–±—ä—ë–º–∞ —Å–Ω–µ–≥–∞ –∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–≤–∏–∂–µ–Ω–∏—è –ø–æ –∫–∞—Ä—Ç–∏–Ω–∫–µ —á–µ—Ä–µ–∑ Gemini.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict, –ø—Ä–∏ –æ—à–∏–±–∫–µ ‚Äî {"error": "..."}.
    """
    try:
        image = Image.open(image_path)

        prompt = (
            "–ù–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≥—Ä—É–∑–æ–≤–æ–π –∞–≤—Ç–æ–º–æ–±–∏–ª—å (–ö–ê–ú–ê–ó –∏–ª–∏ –ø–æ—Ö–æ–∂–∏–π) —Å –∫—É–∑–æ–≤–æ–º.\n"
            "1) –û—Ü–µ–Ω–∏, –Ω–∞ —Å–∫–æ–ª—å–∫–æ –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ –æ—Ç –æ–±—ä—ë–º–∞ –∫—É–∑–æ–≤ –∑–∞–ø–æ–ª–Ω–µ–Ω —Å–Ω–µ–≥–æ–º (0-100).\n"
            "2) –û–ø—Ä–µ–¥–µ–ª–∏ –ù–ê–ü–†–ê–í–õ–ï–ù–ò–ï –¥–≤–∏–∂–µ–Ω–∏—è –≥—Ä—É–∑–æ–≤–∏–∫–∞ –ø–æ –¥–æ—Ä–æ–∂–Ω—ã–º —Å–ª–µ–¥–∞–º, –ø–æ–ª–æ–∂–µ–Ω–∏—é –∫–æ–ª—ë—Å –∏ —Ñ–æ–Ω—É.\n"
            "–í–æ–∑–º–æ–∂–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è:\n"
            '  - \"left_to_right\" ‚Äî –µ—Å–ª–∏ –≥—Ä—É–∑–æ–≤–∏–∫ –µ–¥–µ—Ç —Å–ª–µ–≤–∞ –Ω–∞–ø—Ä–∞–≤–æ\n'
            '  - \"right_to_left\" ‚Äî –µ—Å–ª–∏ –≥—Ä—É–∑–æ–≤–∏–∫ –µ–¥–µ—Ç —Å–ø—Ä–∞–≤–∞ –Ω–∞–ª–µ–≤–æ\n'
            '  - \"unknown\" ‚Äî –µ—Å–ª–∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω–µ–ª—å–∑—è\n\n'
            "–í–∞–∂–Ω–æ: –≤–µ—Ä–Ω–∏ –°–¢–†–û–ì–û –æ–¥–∏–Ω JSON-–æ–±—ä–µ–∫—Ç –ë–ï–ó ``` –∏ –ª—é–±–æ–≥–æ –ª–∏—à–Ω–µ–≥–æ —Ç–µ–∫—Å—Ç–∞:\n"
            '{\n'
            '  "percentage": 0,\n'
            '  "confidence": 0.0,\n'
            '  "direction": "left_to_right"\n'
            "}\n"
        )

        response = gemini_client.models.generate_content(
            model=GEMINI_MODEL,
            contents=[image, prompt],
        )

        text = (response.text or "").strip()

        # –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π —Å—Ä–µ–∑–∞–µ–º ```json ... ```
        if text.startswith("```"):
            text = text.strip("`")
            if text.lower().startswith("json"):
                text = text[4:].strip()

        try:
            data = json.loads(text)
        except Exception:
            data = {"raw": text}

        return data

    except Exception as e:
        print(f"[GEMINI] error: {e}")
        return {"error": str(e)}


def save_analysis_json(image_path: str, timestamp: datetime, gemini_result: dict) -> str:
    """
    –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ —Ä—è–¥–æ–º —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º.
    """
    json_path = image_path.rsplit(".", 1)[0] + ".json"

    payload = {
        "timestamp": timestamp.isoformat(),
        "image_path": image_path,
        "gemini": gemini_result,
    }

    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(payload, f, ensure_ascii=False, indent=2)

    return json_path


def _extract_gemini_fields(gemini_result: dict):
    """
    –î–æ—Å—Ç–∞—ë–º percentage, confidence, direction –∏–∑ –æ—Ç–≤–µ—Ç–∞ Gemini.
    –£–º–µ–µ—Ç –ø–∞—Ä—Å–∏—Ç—å –∏ –ø–æ–ª–µ raw —Å ```json ...``` –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏.
    """
    percentage = None
    confidence = None
    direction = None

    if not isinstance(gemini_result, dict):
        return percentage, confidence, direction

    p = gemini_result.get("percentage")
    c = gemini_result.get("confidence")
    d = gemini_result.get("direction")
    raw = gemini_result.get("raw")

    # –µ—Å–ª–∏ —á–µ–≥–æ-—Ç–æ –Ω–µ—Ç ‚Äî –ø—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å raw
    if (p is None or c is None or d is None) and raw:
        raw_s = str(raw).strip()
        try:
            if raw_s.startswith("```"):
                raw_s = raw_s.strip("`")
                if raw_s.lower().startswith("json"):
                    raw_s = raw_s[4:].strip()
            parsed = json.loads(raw_s)
            if p is None:
                p = parsed.get("percentage")
            if c is None:
                c = parsed.get("confidence")
            if d is None:
                d = parsed.get("direction")
        except Exception:
            pass

    try:
        if p is not None:
            percentage = int(round(float(p)))
    except Exception:
        pass

    try:
        if c is not None:
            confidence = float(c)
    except Exception:
        pass

    if d is not None:
        direction = str(d).strip().lower()

    return percentage, confidence, direction


def send_event_to_backend(image_paths, gemini_result: dict, timestamp: datetime):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–±—ã—Ç–∏–µ –Ω–∞ SnowOps backend.
    –ï—Å–ª–∏ Gemini –≥–æ–≤–æ—Ä–∏—Ç, —á—Ç–æ –º–∞—à–∏–Ω–∫–∞ –ù–ï —Å–ª–µ–≤–∞-–Ω–∞–ø—Ä–∞–≤–æ ‚Äî
    —Å–æ–±—ã—Ç–∏–µ –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º.
    """
    percentage, confidence, direction = _extract_gemini_fields(gemini_result)

    event_payload = {
        "camera_id": CAMERA_ID,
        "event_time": timestamp.replace(microsecond=0).isoformat() + "Z",
        "snow_volume_percentage": percentage,
        "snow_volume_confidence": confidence,
        # –ø—Ä–æ—Å—Ç–æ –ª–æ–≥–∏—Ä—É–µ–º, –Ω–æ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ —Ñ–∏–ª—å—Ç—Ä
        "snow_direction_ai": direction,
    }

    # –§–æ—Ä–º–∏—Ä—É–µ–º files –¥–ª—è multipart/form-data
    files = []
    file_handles = []
    for path in image_paths:
        try:
            f = open(path, "rb")
            file_handles.append(f)
            files.append(("photos", (os.path.basename(path), f, "image/jpeg")))
        except Exception as e:
            print(f"[UPSTREAM] warning: cannot open file {path}: {e}")

    data = {"event": json.dumps(event_payload, ensure_ascii=False)}

    try:
        resp = requests.post(
            BACKEND_ENDPOINT,
            data=data,
            files=files,
            timeout=15,
        )
        status = resp.status_code
        body = resp.text.strip().replace("\n", "")
        print(f"[UPSTREAM] status={status}, body={body}")
        return status, body
    except Exception as e:
        print(f"[UPSTREAM] network_error={e}")
        return None, str(e)
    finally:
        for f in file_handles:
            try:
                f.close()
            except Exception:
                pass


event_sent_for_current_truck = False


def process_video_stream():
    global event_sent_for_current_truck, _last_center_x

    model = init_model()

    cap = cv2.VideoCapture(VIDEO_SOURCE_URL)
    if not cap.isOpened():
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ–ø–æ—Ç–æ–∫:", VIDEO_SOURCE_URL)
        return

    window_name = "Video Stream Analysis"
    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
    cv2.resizeWindow(window_name, DISPLAY_WIDTH, DISPLAY_HEIGHT)

    print("‚úÖ –°—Ç–∞—Ä—Ç –∞–Ω–∞–ª–∏–∑–∞ –≤–∏–¥–µ–æ–ø–æ—Ç–æ–∫–∞... –ù–∞–∂–º–∏ 'q' –¥–ª—è –≤—ã—Ö–æ–¥–∞.")

    frame_width = None
    frame_height = None
    center_start_pixel = None
    center_end_pixel = None
    center_x_geom = None

    fail_count = 0
    MAX_FAILS = 50  # –ø–æ—Å–ª–µ 50 –ø–æ–¥—Ä—è–¥ –Ω–µ—É–¥–∞—á ‚Äî –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–∞–µ–º—Å—è

    while True:
        ret, frame = cap.read()

        # —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–∞–¥—Ä –∂–∏–≤–æ–π
        if not ret or frame is None or frame.size == 0:
            fail_count += 1
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∫–∞–¥—Ä (fail={fail_count})")

            if fail_count >= MAX_FAILS:
                print("üîÅ –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –æ—à–∏–±–æ–∫ —á—Ç–µ–Ω–∏—è, –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –∫–∞–º–µ—Ä–µ...")
                cap.release()
                time.sleep(2)
                cap = cv2.VideoCapture(VIDEO_SOURCE_URL)
                fail_count = 0

            if cv2.waitKey(10) & 0xFF == ord("q"):
                break
            continue

        # —Ç–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –¥–µ–ª–∞—Ç—å –∫–æ–ø–∏—é ¬´—Å—ã—Ç–æ–≥–æ¬ª –∫–∞–¥—Ä–∞
        raw_frame = frame.copy()
        fail_count = 0

        if frame_width is None:
            frame_height, frame_width = frame.shape[:2]
            center_start_pixel = int(frame_width * CENTER_ZONE_START_X)
            center_end_pixel = int(frame_width * CENTER_ZONE_END_X)
            center_x_geom = int(frame_width * CENTER_LINE_X)
            print(f"–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –∫–æ—Ä–∏–¥–æ—Ä: {center_start_pixel}px .. {center_end_pixel}px")

        # –ª–∏–Ω–∏–∏
        cv2.line(frame, (center_x_geom, 0), (center_x_geom, frame_height),
                 (0, 255, 255), 1)
        cv2.line(frame, (center_start_pixel, 0), (center_start_pixel, frame_height),
                 (0, 255, 0), 2)
        cv2.line(frame, (center_end_pixel, 0), (center_end_pixel, frame_height),
                 (0, 255, 0), 2)

        # –¥–µ—Ç–µ–∫—Ü–∏—è –¥–µ–ª–∞–µ–º –ø–æ raw_frame (–±–µ–∑ –ª–∏–Ω–∏–π –∏ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–æ–≤)
        truck_bbox = detect_truck_bbox(raw_frame, model)

        if truck_bbox:
            in_zone, center_x_obj, _, _ = check_center_zone(truck_bbox, frame_width)
            x1, y1, x2, y2 = truck_bbox
            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)

            moving_right = is_moving_left_to_right(center_x_obj)
            print(f"[DBG] center_x={center_x_obj}, last_center={_last_center_x}, "
                f"moving_right={moving_right}, in_zone={in_zone}")


            # —Å—Ä–∞–±–æ—Ç–∞—Ç—å —Ç–æ–ª—å–∫–æ –û–î–ò–ù —Ä–∞–∑ –∑–∞ –ø—Ä–æ—Ö–æ–¥
            if in_zone and moving_right and not event_sent_for_current_truck:
                print("üöõ –ö–∞–º–ê–ó –≤ –∫–æ—Ä–∏–¥–æ—Ä–µ –∏ –¥–≤–∏–∂–µ—Ç—Å—è —Å–ª–µ–≤–∞-–Ω–∞–ø—Ä–∞–≤–æ ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º.")
                image_path, ts = save_frame(raw_frame)
                print("üíæ –ö–∞–¥—Ä —Å–æ—Ö—Ä–∞–Ω—ë–Ω:", image_path)

                gemini_result = analyze_snow_gemini(image_path)
                print("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç Gemini:", gemini_result)

                save_analysis_json(image_path, ts, gemini_result)

                send_event_to_backend([image_path], gemini_result, ts)

                event_sent_for_current_truck = True

        else:
            # –≥—Ä—É–∑–æ–≤–∏–∫ –ø—Ä–æ–ø–∞–ª ‚Äî –≥–æ—Ç–æ–≤–∏–º—Å—è –∫ –Ω–æ–≤–æ–º—É —Å–æ–±—ã—Ç–∏—é
            event_sent_for_current_truck = False
            _last_center_x = None

        resized_frame = cv2.resize(frame, (DISPLAY_WIDTH, DISPLAY_HEIGHT))
        cv2.imshow(window_name, resized_frame)

        key = cv2.waitKey(1) & 0xFF
        if key == ord('q') or key == 27:
            break
        if cv2.getWindowProperty(window_name, cv2.WND_PROP_VISIBLE) < 1:
            break

    cap.release()
    cv2.destroyAllWindows()
    print("‚úÖ –†–∞–±–æ—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")


if __name__ == "__main__":
    process_video_stream()
